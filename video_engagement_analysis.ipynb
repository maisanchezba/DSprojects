{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0be71ec1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ddd869ec642dbe6404672b445fd4dd1",
     "grade": false,
     "grade_id": "cell-6757b7ecd16ad875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Predicting and understanding viewer engagement with educational videos \n",
    "\n",
    "Code to analyse educational video engaging from different features.\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "We extracted training and test datasets of educational video features from the VLE Dataset put together by researcher Sahan Bulathwela at University College London. \n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single educational video, and includes information about diverse properties of the video content as described further below. The target variable is `engagement` which was defined as True if the median percentage of the video watched across all viewers was at least 30%, and False otherwise.\n",
    "\n",
    "\n",
    "For this final assignment, you will bring together what you've learned across all four weeks of this course, by exploring different prediction models for this new dataset. In addition, we encourage you to apply what you've learned about model selection to do hyperparameter tuning using training/validation splits of the training data, to optimize the model and further increase its performance. In addition to a basic evaluation of model accuracy, we've also provided a utility function to visualize which features are most and least contributing to the overall model performance.\n",
    "\n",
    "**File descriptions** \n",
    "    assets/train.csv - the training set (Use only this data for training your model!)\n",
    "    assets/test.csv - the test set\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv:\n",
    "\n",
    "    title_word_count - the number of words in the title of the video.\n",
    "    \n",
    "    document_entropy - a score indicating how varied the topics are covered in the video, based on the transcript. Videos with smaller entropy scores will tend to be more cohesive and more focused on a single topic.\n",
    "    \n",
    "    freshness - The number of days elapsed between 01/01/1970 and the lecture published date. Videos that are more recent will have higher freshness values.\n",
    "    \n",
    "    easiness - A text difficulty measure applied to the transcript. A lower score indicates more complex language used by the presenter.\n",
    "    \n",
    "    fraction_stopword_presence - A stopword is a very common word like 'the' or 'and'. This feature computes the fraction of all words that are stopwords in the video lecture transcript.\n",
    "    \n",
    "    speaker_speed - The average speaking rate in words per minute of the presenter in the video.\n",
    "    \n",
    "    silent_period_rate - The fraction of time in the lecture video that is silence (no speaking).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "* Dataset from: https://github.com/sahanbull/VLE-Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1218318f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7dc38d94db79fb7160854a629c825a8",
     "grade": false,
     "grade_id": "cell-2c0cf4e0ffe5f447",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)   # Do not change this value: required to be compatible with solutions generated by the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d179ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aef89dbca058b3768c5e369581c14bbb",
     "grade": false,
     "grade_id": "cell-f8da4477c345bf17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "9240     0.021111\n",
       "9241     0.030671\n",
       "9242     0.102101\n",
       "9243     0.954662\n",
       "9244     0.023380\n",
       "           ...   \n",
       "11544    0.027166\n",
       "11545    0.016209\n",
       "11546    0.022203\n",
       "11547    0.914186\n",
       "11548    0.020090\n",
       "Length: 2309, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##The first comented function performs a search of optimum parameters based on auc_score and then the uncommented applies this tunning to data.\n",
    "\"\"\"\n",
    "\n",
    "def engagement_model():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    metric=\"roc_auc\"\n",
    "    rec = None\n",
    "    \n",
    "    df = pd.read_csv(\"assets/train.csv\", index_col=\"id\")\n",
    "    X=df.iloc[:,[1,3,6]]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    models=np.array([SVC(), GradientBoostingClassifier(), MLPClassifier()])\n",
    "    grid_vals = np.array([{'kernel': [\"rbf\", \"linear\"],'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]},\n",
    "                          {'learning_rate': [0.001, 0.01, 0.05, 0.1, 1, 10, 100], \"n_estimators\": [5,10,50,100,500]},\n",
    "                          {'hidden_layer_sizes': [[100], [50], [100,100], [50,50]],'alpha': [0.0001, 0.001, 0.01, 0.1]}])#Most important parameters\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "    imp=tree.feature_importances_\n",
    "    \n",
    "    grid_clf_auc = GridSearchCV(models[1], param_grid = grid_vals[1], scoring = metric, cv=2)\n",
    "    grid_clf_auc.fit(X_train, y_train)\n",
    "    y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test) \n",
    "\n",
    "    print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "    print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "    print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "    \n",
    "    return grid_vals\n",
    "engagement_model()\n",
    "\n",
    "Test set AUC:  0.8513744982114587\n",
    "Grid best parameter (max. AUC):  {'learning_rate': 0.01, 'n_estimators': 500}\n",
    "Grid best score (AUC):  0.8353437378545192\n",
    "\n",
    "\"\"\"\n",
    "def engagement_model():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    metric=\"roc_auc\"\n",
    "    \n",
    "    df = pd.read_csv(\"assets/train.csv\", index_col=\"id\")\n",
    "    test = pd.read_csv(\"assets/test.csv\", index_col=\"id\")\n",
    "    X=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    models=np.array([SVC(), GradientBoostingClassifier(), MLPClassifier()])\n",
    "    grid_vals = np.array([{'kernel': [\"rbf\", \"linear\"],'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]},\n",
    "                          {'learning_rate': [0.001, 0.01, 0.05, 0.1, 1, 10, 100], \"n_estimators\": [5,10,50,100,500]},\n",
    "                          {'hidden_layer_sizes': [[100], [50], [100,100], [50,50]],'alpha': [0.0001, 0.001, 0.01, 0.1]}])#Most important parameters\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "    imp=tree.feature_importances_\n",
    "    \n",
    "    \"\"\"for i in range(len(models)):\n",
    "        grid_clf_auc = GridSearchCV(models[i], param_grid = grid_vals[i], scoring = metric)\n",
    "        grid_clf_auc.fit(X_train, y_train)\n",
    "        y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test) \n",
    "\n",
    "        print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "        print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "        print('Grid best score (AUC): ', grid_clf_auc.best_score_)\"\"\"\n",
    "    \n",
    "    winner=GradientBoostingClassifier(learning_rate= 0.01, n_estimators= 500).fit(X_train, y_train)\n",
    "    rec=test.iloc[:,-1]\n",
    "    \n",
    "    return pd.Series(winner.predict_proba(test)[:,1], index=rec.index)\n",
    "engagement_model()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
