{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7109c4020fb6a8bcaef37e41e738e03d",
     "grade": false,
     "grade_id": "cell-dcb6ef72e08dd5fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Spam identifier\n",
    "Exploration of text message data and creation of models to predict if a message is spam or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97714be9ccaf89bbff57d64a249680b8",
     "grade": false,
     "grade_id": "cell-f403cc37f510e3b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0\n",
       "5  FreeMsg Hey there darling it's been 3 week's n...       1\n",
       "6  Even my brother is not like to speak with me. ...       0\n",
       "7  As per your request 'Melle Melle (Oru Minnamin...       0\n",
       "8  WINNER!! As a valued network customer you have...       1\n",
       "9  Had your mobile 11 months or more? U R entitle...       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spam_data = pd.read_csv('assets/spam.csv')\n",
    "\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)\n",
    "spam_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8458ef46cc0956f75d602cfadbb125f8",
     "grade": false,
     "grade_id": "cell-73f5a763723ca5b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], \n",
    "                                                    spam_data['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2793aeb56f0b9f5455a8022808ce2c68",
     "grade": false,
     "grade_id": "cell-2707cd8ee068d8d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.406317300789663"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_of_spam():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return 100/2 *spam_data[spam_data['target']==1].size/spam_data['target'].size\n",
    "\n",
    "percentage_of_spam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "978982d101ec080d93ae0fbceb856df2",
     "grade": false,
     "grade_id": "cell-d6823cd2d4b78595",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99154542213469599"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%precision 17\n",
    "\n",
    "def model_count():\n",
    "    vect = CountVectorizer().fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    y_p=model.predict_proba(vect.transform(X_test))[:,-1]\n",
    "    return roc_auc_score(y_test, y_p)#Your answer here\n",
    "\n",
    "model_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e40c91cd89e25cecdcb123bb447dadd1",
     "grade": false,
     "grade_id": "cell-cf833ad4436ff594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Second vectroizer\n",
    "\n",
    "Fit and transform the training data `X_train` using a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than **3**.\n",
    "\n",
    "Then fit a multinomial Naive Bayes classifier model with smoothing `alpha=0.1` and compute the area under the curve (AUC) score using the transformed test data.\n",
    "\n",
    "*This function should return the AUC score as a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8679a4b2f417981c7f2163a0fa692866",
     "grade": false,
     "grade_id": "cell-4f8dc958e73ebf9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954968337775665"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision 16\n",
    "def model_tfid():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    y_p=model.predict_proba(vect.transform(X_test))[:,-1]\n",
    "    return roc_auc_score(y_test, y_p)\n",
    "\n",
    "model_tfid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ae20c6a5ea3577daaff67026ada729d",
     "grade": false,
     "grade_id": "cell-142fa11bdbd6c041",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "The following function has been provided to help you combine new features into the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d03fff196791b604effa8f3738498b59",
     "grade": false,
     "grade_id": "cell-b1b59ae1895c1675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4388967b5944a88ddb4ba6ce1ee787bc",
     "grade": false,
     "grade_id": "cell-157cfd481d53666e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## An aditional feaure\n",
    "\n",
    "Fit and transform the training data X_train using a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than **5**.\n",
    "\n",
    "Using this document-term matrix and an additional feature, **the length of document (number of characters)**, fit a Support Vector Classification model with regularization `C=10000`. Then compute the area under the curve (AUC) score using the transformed test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3308c695dc06f58ad0471f643e787794",
     "grade": false,
     "grade_id": "cell-8bd2ea8cadce6a40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963202213809143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def model():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_train_unvectorized = vect.inverse_transform(X_train_vectorized)\n",
    "    \n",
    "    spam=np.array(X_train)\n",
    "    len_feature=np.array([len(w) for w in spam])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, len_feature)\n",
    "    \n",
    "    model = SVC(C=10000)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    x_add=vect.transform(X_test)\n",
    "    spam2=np.array(X_test)\n",
    "    len_featuret=np.array([len(w) for w in spam2])\n",
    "    x_add = add_feature(x_add, len_featuret)\n",
    "    y_p=model.decision_function(x_add)\n",
    "    return roc_auc_score(y_test, y_p)\n",
    "    #return X_train_unvectorized\n",
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c12a31611d9f66f872fd93daf94889a8",
     "grade": false,
     "grade_id": "cell-1ddf2c6c108f6a85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Feature: **number of digits per document**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "752f6ba55e9ea2c42030a0bef42d7bc0",
     "grade": false,
     "grade_id": "cell-bbd73da89641f28d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972921582941445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def answer_nine():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    vect = TfidfVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_train_unvectorized = vect.inverse_transform(X_train_vectorized)\n",
    "    \n",
    "    spam=np.array(X_train)\n",
    "    len_feature=np.array([len(w) for w in spam])\n",
    "    n_digits=np.array([sum(c.isdigit() for c in s) for s in spam])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, len_feature)\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, n_digits)\n",
    "    \n",
    "    model = LogisticRegression(C=100, max_iter=1000)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    X_test_vectorized=vect.transform(X_test)\n",
    "    spam_test=np.array(X_test)\n",
    "    len_feature_test=np.array([len(w) for w in spam_test])\n",
    "    n_digits_test=np.array([sum(c.isdigit() for c in s) for s in spam_test])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, len_feature_test)\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, n_digits_test)\n",
    "    y_p=model.predict_proba(X_test_vectorized)[:,-1]\n",
    "    return roc_auc_score(y_test, y_p)\n",
    "\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4aad0115bf7fe21b470680010fde6246",
     "grade": false,
     "grade_id": "cell-733de6a9548fe648",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Using n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5efa62b1d9cf26ce2beb28db30c1b83",
     "grade": false,
     "grade_id": "cell-1233becfd19fff26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9890 is out of bounds for axis 0 with size 9889",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vect\u001b[38;5;241m.\u001b[39mget_feature_names())\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (AUC, feature_names[sorted_coef[:\u001b[38;5;241m10\u001b[39m]], feature_names[sorted_coef[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m11\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m---> 38\u001b[0m \u001b[43manswer_eleven\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 37\u001b[0m, in \u001b[0;36manswer_eleven\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m sorted_coef \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margsort()\n\u001b[1;32m     36\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vect\u001b[38;5;241m.\u001b[39mget_feature_names())\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (AUC, feature_names[sorted_coef[:\u001b[38;5;241m10\u001b[39m]], \u001b[43mfeature_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_coef\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9890 is out of bounds for axis 0 with size 9889"
     ]
    }
   ],
   "source": [
    "def answer_eleven():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import re\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    vect = CountVectorizer(min_df=5, ngram_range=(2,5), analyzer='char_wb').fit(X_train[:2000])\n",
    "    X_train_vectorized = vect.transform(X_train[:2000])\n",
    "    X_train_unvectorized = vect.inverse_transform(X_train_vectorized)\n",
    "    \n",
    "    spam=np.array(X_train[:2000])\n",
    "    len_feature=np.array([len(w) for w in spam])\n",
    "    n_digits=np.array([sum(c.isdigit() for c in s) for s in spam])\n",
    "    non_word=np.array([len(re.sub('[\\w]+' ,'', s)) for s in spam])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, len_feature)\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, n_digits)\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, non_word)\n",
    "    \n",
    "    model = LogisticRegression(C=100, max_iter=1000)\n",
    "    model.fit(X_train_vectorized, y_train[:2000])\n",
    "    \n",
    "    X_test_vectorized=vect.transform(X_test)\n",
    "    spam_test=np.array(X_test)\n",
    "    len_feature_test=np.array([len(w) for w in spam_test])\n",
    "    n_digits_test=np.array([sum(c.isdigit() for c in s) for s in spam_test])\n",
    "    non_word_test=np.array([len(re.sub('[\\w]+' ,'', s)) for s in spam_test])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, len_feature_test)\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, n_digits_test)\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, non_word_test)\n",
    "    \n",
    "    y_p=model.predict_proba(X_test_vectorized)[:,-1]\n",
    "    AUC=roc_auc_score(y_test, y_p)\n",
    "    \n",
    "    sorted_coef = model.coef_[0].argsort()\n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    return (AUC, feature_names[sorted_coef[:10]], feature_names[sorted_coef[:-11:-1]])\n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "478c0c9b96fa606218d12419d35cb768",
     "grade": true,
     "grade_id": "cell-477ea85f5bcd7cef",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "Pn19K",
   "launcher_item_id": "y1juS",
   "part_id": "ctlgo"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
